### Imports
import streamlit as st
from langchain.agents import AgentType, initialize_agent
from langchain.chat_models import ChatOpenAI
from langchain.tools import BaseTool, StructuredTool, Tool, tool
from langchain.llms import OpenAI
from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner
from langchain import LLMMathChain
from langchain import PromptTemplate, LLMChain
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
import os
import openai
import io
from contextlib import redirect_stdout

# import json
# import requests
# import pandas as pd
# from typing import Optional, Type
# import time
# from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun
# from langchain.tools import DuckDuckGoSearchRun
# from langchain import SerpAPIWrapper
# from langchain.prompts.chat import (
#     ChatPromptTemplate,
#     SystemMessagePromptTemplate,
#     AIMessagePromptTemplate,
#     HumanMessagePromptTemplate,
# )
# from langchain.schema import (
#     AIMessage,
#     HumanMessage,
#     SystemMessage
# )
# from langchain.agents import AgentExecutor


### CSS
st.set_page_config(
    page_title='GAMEPLAN', 
    layout="wide",
    initial_sidebar_state='collapsed',
)
padding_top = 0
st.markdown(f"""
    <style>
        .block-container, .main {{
            padding-top: {padding_top}rem;
        }}
    </style>
    """,
    unsafe_allow_html=True,
)

# OpenAI Credentials
if not os.environ["OPENAI_API_KEY"]:
    openai_api_key = st.secrets["OPENAI_API_KEY"]
else:
    openai_api_key = os.environ["OPENAI_API_KEY"]

### UI
""
col1, col2 = st.columns( [1,5] )
col1.image('628858.png', width=170)
col2.title('GamePlan')
col2.subheader('Generative AI Managed Enterprise PLAtform Network')
# st.markdown('---')

def change_q(myquestion):
    promt = myquestion

with st.sidebar: 
    mysidebar = st.selectbox('Select GamePlan', ['Cybersecurity', 'Data Science', 'Tour Guide'])
    if mysidebar == 'Cybersecurity':
        show_detail = st.checkbox('Show Details')
        st.markdown("---")
        st.markdown("### Standard Questions:")
        st.button('Find Threats', on_click=change_q, args=['Who are out insider threats?'])
    if mysidebar == 'Tour Guide':
        st.markdown("---")
        st.markdown("### Planner Chain:")
        st.markdown("&nbsp;&nbsp;&nbsp; Vector Search")
        st.markdown("### Executor Chain:")
        st.markdown("&nbsp;&nbsp;&nbsp; Vector Search")
        st.markdown("&nbsp;&nbsp;&nbsp; Internet Search")
    if mysidebar == 'Data Science':
        st.markdown("---")
        st.markdown("### Planner Chain:")
        st.markdown("&nbsp;&nbsp;&nbsp; Internet Search")
        st.markdown("### Executor Chain:")
        st.markdown("&nbsp;&nbsp;&nbsp; Python")
        st.markdown("&nbsp;&nbsp;&nbsp; SQL")
        st.markdown("&nbsp;&nbsp;&nbsp; Pandas")
        st.markdown("&nbsp;&nbsp;&nbsp; Memory")

if mysidebar == 'Cybersecurity':
    with st.expander("**:blue[Cybersecurity Overvew]**"):
        st.markdown("**:blue[The cybersecurity model uses a Planner/Executor SuperChain.]**")
        st.markdown("**:blue[The workflow first enters the Planner phase where it uses vector semantic KNN search of our CSIO's cybersecurity document to determine how to answer the question. This document resembles an FAQ document and provides steps for completing these tasks. These are tasks a human might take. The LLM will translate these steps into steps that LangChain can execute.]**")
        st.markdown("**:blue[In the Executor phase the LLM instructs LangChain how to perform each step. Answers from each step are preserved and a final answer is generated by the LLM to the proposed questions. For this demo LLM largely relies on SQL queries. However, the workflow could include other operations including dynamic Python using SciKit, querying the internet, running shell scripts, running REST queries, or any act that might be defined in the CSIO's document.]**")

        col1, col2, col3 = st.columns([15, 70, 15])
        col2.image('cyber.jpg',caption='LangChain Structure')

    st.markdown('---')

    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input(placeholder="Ask a cybersecurity question?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        ### Bring in my controlling documents and the additonal template
        with open('content/cybersecurity.txt') as f:
            tasks = f.readlines()
        mytasks = str(tasks)    
        template=f"""You are a cybersecurity expert. 
        Provide an answer to the "Question" below. 
        To answer this question, follow the "Steps" below and write a final conclusion based upon the results of the last step.
        When you respond to an action indicate the type of response by beginging with "Thought:", "Observation:", or "Final answer:".
        If you can't answer the question return the answer: "Sorry, but I can't help you with that task."

        text:
        {mytasks}

        Question:
        {prompt}
        """
        ### Build an agent that can be used to run SQL queries against the database
        llm = ChatOpenAI(model="gpt-4", temperature=0, verbose=False)
        # db_dir = "content/chinook.sqlite"
        # mydb = SQLDatabase.from_uri("sqlite:///" + os.path.abspath(db_dir))
        # st.write("sqlite:///" + os.path.abspath(db_dir))
        mydb = SQLDatabase.from_uri("sqlite:///chinook.sqlite")
        toolkit = SQLDatabaseToolkit(db=mydb, llm=llm)

        sql_agent = create_sql_agent(
            llm=llm, #OpenAI(temperature=0),
            toolkit=toolkit,
            verbose=False
        )

        ### Build an agent that can perform mathematics...not used but provided as an example.
        llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=False)

        ### Build a chain from the three tools
        tools = [
            Tool(
                name="Calculator",
                func=llm_math_chain.run,
                description="useful for when you need to answer questions about math"
            ),
            Tool(
                name="SQL",
                func=sql_agent.run,
                description="""This tool queries a SQLite database. It is useful for when you need to answer questions 
                by running SQLite queries. Always indicate if your response is a "thought" or a "final answer". 
                The following table information is provided to help you write your sql statement:
                
                apache_logs: (ID, ip, user, dt, tz, vrb, uri, resp, byt, referer, useragent)
                emails: (send_date, from_name, to_name, subject, body, attachment_type, filesize, sentiment)
                """
            )
        ]

        planner = load_chat_planner(llm)
        executor = load_agent_executor(
            llm, 
            tools, 
            verbose=True,
        )
        pe_agent = PlanAndExecute(
            planner=planner, 
            executor=executor,  
            verbose=True, 
            max_iterations=2,
        )

        if show_detail:
            f = io.StringIO()
            with redirect_stdout(f):
                with st.spinner("Processing..."):
                    response = pe_agent(template)
        else:
            with st.spinner("Processing..."):
                response = pe_agent(template)

        st.session_state.messages.append({"role": "assistant", "content": response['output']})    
        st.chat_message('assistant').write(response['output'])

        if show_detail:
            with st.expander('Details', expanded=False):
                s = f.getvalue()
                st.write(s)
            
if mysidebar == 'Tour Guide':
    from langchain.embeddings.openai import OpenAIEmbeddings
    from langchain.llms import OpenAI
    import openai
    from langchain.chains import LLMChain
    import chromadb
    from chromadb.config import Settings
    from langchain import PromptTemplate
    chroma_client = chromadb.Client(Settings(
        chroma_db_impl="duckdb+parquet",
        persist_directory="content" # Optional, defaults to .chromadb/ in the current directory
    ))
    battle = chroma_client.get_collection(name="battleinfo", embedding_function=OpenAIEmbeddings())
    geodata = chroma_client.get_collection(name="geodata", embedding_function=OpenAIEmbeddings())     

    prompt_template = """Use the context below to write a 1000 word answer to the question asked. 
    If you aren't sure of the answer then respond 'I don't know the answer':
        Context: {context}
        Question: {question}
        Blog post:"""

    PROMPT = PromptTemplate(
        template=prompt_template, input_variables=["context", "question"]
    )

    llm = OpenAI(temperature=.7, max_tokens=2500)

    chain = LLMChain(llm=llm, prompt=PROMPT)

    def tour_guide(
        question: str = "",
        lat_long: list = "",
        mystyle: str = 'location'):
        if lat_long:
            results = geodata.query(
                query_embeddings=lat_long,
                n_results=1,
                where={"style": mystyle})
            return results['documents'][0][0]
        else:
            response = openai.Embedding.create(
            input=question,
            model="text-embedding-ada-002"
            )
            qembeddings = response['data'][0]['embedding']
            results = battle.query(
                query_embeddings=qembeddings,
                n_results=5)

            all_text = ""
            for x in results['documents'][0]:
                all_text = all_text + "\n\n" + x

            inputs = [{"context": all_text, "question": question}]
            myoutput = chain.apply(inputs)
            return myoutput[0]['text'].strip()

    st.markdown("### **:blue[Overview:]** ")
    st.markdown("**:blue[This gameplan can be used in the use case of tour guides or situations where an expert/sherpa needs to guide the user.]**")
    runlocal = st.button('What Happened Here?', type='primary')
    myquestion = st.text_input('Question', placeholder='Ask your tour guide?')
    myanswer = ''
    if runlocal:
        mylatlong = [39.81537349036316, -77.23534021584484]
        runlocal = ''
        myquestion = ''
        with st.spinner('Running LangChain...Please Wait...'):
            myanswer = tour_guide(lat_long = mylatlong)
    else:
        mylatlong = ''
        if myquestion:
            with st.spinner('Running LangChain...Please Wait...'):
                myanswer = tour_guide(question = myquestion)

    if myanswer:
        st.write("Answer:")
        st.write(myanswer)

    st.markdown('---')
    with st.expander("See explanation"):
        st.markdown("**:blue[The tourguide model uses an augmented Planner/Executor SuperChain.]**")
        st.markdown("**:blue[Python determines if the user has submitted lat/long coordinates (such as when they hit the \[What happened here?\] button. If the user proposes a question, their location is determined and local areas of interest are used in the prompt to augment the answer. This then launches the Planner chain.]**")
        st.markdown("**:blue[In the Executor phase the LLM performs a vector semantic KNN search of uploaded content to answer the user's question.]**")

        col1, col2, col3 = st.columns([15, 70, 15])
        col2.image('tour.jpg',caption='LangChain Structure')
        col1b, col2b, col3b = st.columns([15, 70, 15])
        col2b.image('map.jpg',caption='Gettysburg - Around Pickett\'s Charge')
        col2b.image('IMG_2732.jpg',caption='Bryan Farm and 111th NY')

if mysidebar == 'Data Science':
    from langchain.agents.agent_toolkits import create_python_agent
    from langchain.tools.python.tool import PythonREPLTool
    from langchain.python import PythonREPL
    from langchain.llms.openai import OpenAI

    agent_executor = create_python_agent(
        llm=OpenAI(temperature=0, max_tokens=1000),
        tool=PythonREPLTool(),
        verbose=True
    )

    st.markdown("### **:blue[Overview:]** ")
    st.markdown("**:blue[This gameplan is used to answer questions where dynamic Python is required. It also has the ability to query databases to extract the data necessary for the analysis.]**")
    st.markdown("**:blue[It can write regular python, SciKit, Pytorch...for example, ask *'write a single neuron neural network in PyTorch. Take synthetic data for y=2x. Train for 1000 epochs and print every 100 epochs. Return prediction for x = 5'*]**")
    myquestion = st.text_input('Question', placeholder='Ask a question?', value="What is the 10th fibonacci number?")

    if myquestion:
        with st.spinner('Running LangChain...Please Wait...'):
            myresults = agent_executor.run(myquestion)
            st.write(myresults)

    st.markdown('---')
    with st.expander("See explanation"):
        st.markdown("**:blue[A Planner/Executor SuperChain is used in this model. In the Planner phase, the LLM searches the internet to determine how to solve the problem. It then developes a set of steps for the Executor phase.]**")
        st.markdown("**:blue[In the Executor phase the LLM instructs LangChain how to perform each step. The chain has access to the data lakehouse, dynamic Python, a Pandas tool, and a memory tool so data can be moved between tools.]**")

        col1, col2, col3 = st.columns([15, 70, 15])
        col2.image('python.jpg',caption='LangChain Structure')
